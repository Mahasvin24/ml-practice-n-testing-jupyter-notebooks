{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3c8517",
   "metadata": {},
   "source": [
    "This notebook is some of the testing out of concepts and practice I did following along with\n",
    "\n",
    "### Assembly AI's \"PyTorch Crash Course - Getting Started with Deep Learning\"\n",
    "\n",
    "at the link:\n",
    "\n",
    "https://www.youtube.com/watch?v=OIenNRt2bjg\n",
    "\n",
    "The video doesn't conver concepts, just code implementation, which is great for me when trying\n",
    "to switch from tensorflow to pytorch.\n",
    "\n",
    "Practice Notebook Concepts:\n",
    "1. Tensor Basics\n",
    "2. Autograd w/ torch\n",
    "3. Neural Network (for MNIST)\n",
    "4. CNN (for MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making arrays / matricies / tensors\n",
    "x1 = torch.empty(3, 3, 3)\n",
    "x2 = torch.zeros(5)\n",
    "x3 = torch.ones(5)\n",
    "x4 = torch.rand(5, dtype=torch.float16)\n",
    "\n",
    "# Shape / size\n",
    "a = x1.size()\n",
    "b = x1.shape\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# Tensors\n",
    "x = torch.tensor([5, 3], requires_grad=True) # requires_grad tells torch whether you need it to calculate gradient for later (defualt is False)\n",
    "y = torch.tensor([4, 9])\n",
    "\n",
    "print(x + y) # element wise addition\n",
    "print(y.add(x))\n",
    "print(y)\n",
    "print(y.add_(x)) # adding in place\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb4648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing\n",
    "x = torch.rand(5, 3)\n",
    "print(x[:, 0]) # all rows, column 0\n",
    "print(x[1, :]) # first row, all columns\n",
    "print(x[1, 1]) # --> returns a tensor\n",
    "print(x[1, 1].item()) # --> returns a float value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d470e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) # -1 tells torch to figure it out based on other dims\n",
    "\n",
    "print(x.shape[0], y.shape, z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc7975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch to numpy\n",
    "# Note: If the tensor is on the CPU (instead of GPU) \n",
    "# both objects will share memory, so changing one \n",
    "# changes the other.\n",
    "t = torch.ones(4)\n",
    "n = t.numpy()\n",
    "t[0] = 2\n",
    "print(f\"{t}\\n{n}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b724d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy to torch\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n) # points to same array\n",
    "t2 = torch.tensor(n) # makes a copy of array \n",
    "n[0] = 2\n",
    "\n",
    "print(f\"{n}\\n{t}\\n{t2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1672e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "device = torch.device(\"mps\")\n",
    "n = np.ones(5, dtype=np.float32)\n",
    "t = torch.zeros(3, 3, 3,).to(device) # make on CPU, move to GPU\n",
    "t2 = torch.zeros(3, 3, 3, device=device)\n",
    "n[0] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068fe9ba",
   "metadata": {},
   "source": [
    "### 2. Autograd - The autograd package provide automatic differentiation. (Applies partial derivatives while applying the chain rule.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([3.0], requires_grad=True)\n",
    "y = x ** 2 + 2\n",
    "\n",
    "y.sum().backward() # does all the backprop\n",
    "print(x.grad) # dy/dx\n",
    "\n",
    "\"\"\"\n",
    "!!! backward() accumulates the gradient for this tesnor into .grad !!!\n",
    "!!! make sure to clear this each time with optimizer.zero_grad() !!!\n",
    "\"\"\"\n",
    "\n",
    "# To stop autograd:\n",
    "# x.requires_grad_(False)\n",
    "# x.detach() - creates a copy with requires_grad=False\n",
    "# wrap in \"with torch.no_grad():\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb18b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Linear Regression with Autograd \"\"\"\n",
    "\n",
    "# Training examples (actual model should give y = 2 * x)\n",
    "X = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8, 10, 12, 14, 16], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# forward method\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss (using mean squared error, MSE)\n",
    "def loss(y, y_hat):\n",
    "    return ((y - y_hat) ** 2).mean()\n",
    "\n",
    "X_test = 5.0\n",
    "\n",
    "print(f\"Starting prediction: {X_test} --> {forward(X_test)}\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = forward(X) # prediction tensor of all training examples\n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # Finding all gradients\n",
    "    l.backward()\n",
    "\n",
    "    # Gradient descent (for one var)\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "\n",
    "    # Emptying gradients\n",
    "    w.grad.zero_()\n",
    "\n",
    "    # Progress check\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}: w = {w.item():.3f}, loss = {l:.3f}\")\n",
    "\n",
    "print(f\"Prediction: f({X_test} = {forward(X_test).item():.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b143e92",
   "metadata": {},
   "source": [
    "### 3. Model, Loss, & Optimizer\n",
    "\n",
    "Typical PyTorch pipeline:\n",
    "\n",
    "1. Design mode (input --> forward pass thru layers --> output)\n",
    "2. Construct loss and optimizer\n",
    "3. Training loop:\n",
    "    - Forwards (computer prediction and loss)\n",
    "    - Backward (compute gradeints)\n",
    "    - Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c56fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples = 8, features = 1\n",
      "Pre-training Prediction: f(20.000) = 40.000\n",
      "Epoch 10: w = 2.000, loss = 0.046\n",
      "Epoch 20: w = 2.000, loss = 0.042\n",
      "Epoch 30: w = 2.000, loss = 0.039\n",
      "Epoch 40: w = 2.000, loss = 0.036\n",
      "Epoch 50: w = 2.000, loss = 0.033\n",
      "Epoch 60: w = 2.000, loss = 0.031\n",
      "Epoch 70: w = 2.000, loss = 0.028\n",
      "Epoch 80: w = 2.000, loss = 0.026\n",
      "Epoch 90: w = 2.000, loss = 0.024\n",
      "Epoch 100: w = 2.000, loss = 0.022\n",
      "Prediction: f(tensor([[20.]], requires_grad=True) = 40.838)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Column vectors for training and target values\n",
    "X = torch.tensor([[1], [2], [3], [4], [5], [6], [7], [8]], dtype=torch.float32) \n",
    "Y = torch.tensor([[2], [4], [6], [8], [10], [12], [14], [16]], dtype=torch.float32)\n",
    "\n",
    "# Shape\n",
    "n_samples, n_features = X.shape\n",
    "print(f\"samples = {n_samples}, features = {n_features}\")\n",
    "\n",
    "# Test set\n",
    "X_test = torch.tensor([[20]], dtype=torch.float32, requires_grad=True)\n",
    "Y_test = torch.tensor([[40]], dtype=torch.float32)\n",
    "\n",
    "# 1) Design the Model\n",
    "class LinearRegression(nn.Module): # inherits from nn.Module --> base class for all neural networks\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__() # setting up important stuff using superconstructor\n",
    "        self.lin = nn.Linear(input_dim, output_dim) # one linear layer\n",
    "\n",
    "    def forward(self, x): # place to apply each layer\n",
    "        return self.lin(x)\n",
    "    \n",
    "input_size = output_size = n_features\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "print(f\"Pre-training Prediction: f({X_test.item():.3f}) = {Y_test.item():.3f}\")\n",
    "\n",
    "# 2) Define loss and optimizer\n",
    "learning_rate = 0.01\n",
    "n_epochs = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # SGD --> stochastic gradient descent\n",
    "\n",
    "# 3) Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    # Forwards pass\n",
    "    Y_hat = model(X)\n",
    "\n",
    "    # Calculate loss\n",
    "    l = loss(Y, Y_hat)\n",
    "\n",
    "    # Backprop\n",
    "    l.backward()\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Clearing gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Progress check\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}: w = {w.item():.3f}, loss = {l:.3f}\")\n",
    "\n",
    "print(f\"Prediction: f({X_test} = {model(X_test).item():.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac98ada7",
   "metadata": {},
   "source": [
    "#### 4. Creating a NN\n",
    "\n",
    "Same process as step 3, but multiple layers.\n",
    "\n",
    "Concepts:\n",
    "GPU use, Datasets, Dataloader, Transforms, Neural Net, Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b9ca95da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Hyper-parameters\n",
    "input_size = 784 # 28x28 MNIST images\n",
    "hidden_size = 500 # number of neurons in the hidden layer\n",
    "num_classes = 10 # number of outputs (or classes), 10, since we have 10 digits\n",
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Fetching dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\",                     # from data folder\n",
    "    train=True,                        # extract training data and\n",
    "    transform=transforms.ToTensor(),   # convert to a tensor.\n",
    "    download=False                      # download data on this device (if it's not already there)\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\",                   # from data folder\n",
    "    train=False,                     # extract non-training (test data) (10k examples)\n",
    "    transform=transforms.ToTensor(),  # convert to a tensor\n",
    "    download=False\n",
    ")\n",
    "\n",
    "# Data loaders --> helps batch, shuffle, and feed data into the model\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "examples = iter(test_loader)\n",
    "example_data, example_targets = next(examples)\n",
    "\n",
    "r = 1\n",
    "c = 10\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "for i in range(r * c):\n",
    "    plt.subplot(r, c, i + 1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c989fc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Step [100/600], Loss: 0.193\n",
      "Epoch 1: Step [200/600], Loss: 0.306\n",
      "Epoch 1: Step [300/600], Loss: 0.384\n",
      "Epoch 1: Step [400/600], Loss: 0.310\n",
      "Epoch 1: Step [500/600], Loss: 0.242\n",
      "Epoch 1: Step [600/600], Loss: 0.224\n",
      "Epoch 2: Step [100/600], Loss: 0.108\n",
      "Epoch 2: Step [200/600], Loss: 0.125\n",
      "Epoch 2: Step [300/600], Loss: 0.178\n",
      "Epoch 2: Step [400/600], Loss: 0.149\n",
      "Epoch 2: Step [500/600], Loss: 0.133\n",
      "Epoch 2: Step [600/600], Loss: 0.186\n",
      "Epoch 3: Step [100/600], Loss: 0.067\n",
      "Epoch 3: Step [200/600], Loss: 0.081\n",
      "Epoch 3: Step [300/600], Loss: 0.099\n",
      "Epoch 3: Step [400/600], Loss: 0.086\n",
      "Epoch 3: Step [500/600], Loss: 0.083\n",
      "Epoch 3: Step [600/600], Loss: 0.153\n",
      "Epoch 4: Step [100/600], Loss: 0.046\n",
      "Epoch 4: Step [200/600], Loss: 0.052\n",
      "Epoch 4: Step [300/600], Loss: 0.059\n",
      "Epoch 4: Step [400/600], Loss: 0.046\n",
      "Epoch 4: Step [500/600], Loss: 0.053\n",
      "Epoch 4: Step [600/600], Loss: 0.122\n",
      "Epoch 5: Step [100/600], Loss: 0.031\n",
      "Epoch 5: Step [200/600], Loss: 0.032\n",
      "Epoch 5: Step [300/600], Loss: 0.037\n",
      "Epoch 5: Step [400/600], Loss: 0.027\n",
      "Epoch 5: Step [500/600], Loss: 0.037\n",
      "Epoch 5: Step [600/600], Loss: 0.095\n",
      "Epoch 6: Step [100/600], Loss: 0.022\n",
      "Epoch 6: Step [200/600], Loss: 0.022\n",
      "Epoch 6: Step [300/600], Loss: 0.031\n",
      "Epoch 6: Step [400/600], Loss: 0.016\n",
      "Epoch 6: Step [500/600], Loss: 0.025\n",
      "Epoch 6: Step [600/600], Loss: 0.071\n",
      "Epoch 7: Step [100/600], Loss: 0.013\n",
      "Epoch 7: Step [200/600], Loss: 0.012\n",
      "Epoch 7: Step [300/600], Loss: 0.025\n",
      "Epoch 7: Step [400/600], Loss: 0.013\n",
      "Epoch 7: Step [500/600], Loss: 0.018\n",
      "Epoch 7: Step [600/600], Loss: 0.048\n",
      "Epoch 8: Step [100/600], Loss: 0.006\n",
      "Epoch 8: Step [200/600], Loss: 0.007\n",
      "Epoch 8: Step [300/600], Loss: 0.020\n",
      "Epoch 8: Step [400/600], Loss: 0.018\n",
      "Epoch 8: Step [500/600], Loss: 0.016\n",
      "Epoch 8: Step [600/600], Loss: 0.029\n",
      "Epoch 9: Step [100/600], Loss: 0.004\n",
      "Epoch 9: Step [200/600], Loss: 0.005\n",
      "Epoch 9: Step [300/600], Loss: 0.009\n",
      "Epoch 9: Step [400/600], Loss: 0.007\n",
      "Epoch 9: Step [500/600], Loss: 0.015\n",
      "Epoch 9: Step [600/600], Loss: 0.008\n",
      "Epoch 10: Step [100/600], Loss: 0.003\n",
      "Epoch 10: Step [200/600], Loss: 0.006\n",
      "Epoch 10: Step [300/600], Loss: 0.011\n",
      "Epoch 10: Step [400/600], Loss: 0.007\n",
      "Epoch 10: Step [500/600], Loss: 0.005\n",
      "Epoch 10: Step [600/600], Loss: 0.003\n",
      "Epoch 11: Step [100/600], Loss: 0.002\n",
      "Epoch 11: Step [200/600], Loss: 0.005\n",
      "Epoch 11: Step [300/600], Loss: 0.006\n",
      "Epoch 11: Step [400/600], Loss: 0.005\n",
      "Epoch 11: Step [500/600], Loss: 0.012\n",
      "Epoch 11: Step [600/600], Loss: 0.007\n",
      "Epoch 12: Step [100/600], Loss: 0.004\n",
      "Epoch 12: Step [200/600], Loss: 0.006\n",
      "Epoch 12: Step [300/600], Loss: 0.028\n",
      "Epoch 12: Step [400/600], Loss: 0.009\n",
      "Epoch 12: Step [500/600], Loss: 0.004\n",
      "Epoch 12: Step [600/600], Loss: 0.005\n",
      "Epoch 13: Step [100/600], Loss: 0.007\n",
      "Epoch 13: Step [200/600], Loss: 0.001\n",
      "Epoch 13: Step [300/600], Loss: 0.005\n",
      "Epoch 13: Step [400/600], Loss: 0.003\n",
      "Epoch 13: Step [500/600], Loss: 0.046\n",
      "Epoch 13: Step [600/600], Loss: 0.022\n",
      "Epoch 14: Step [100/600], Loss: 0.005\n",
      "Epoch 14: Step [200/600], Loss: 0.006\n",
      "Epoch 14: Step [300/600], Loss: 0.006\n",
      "Epoch 14: Step [400/600], Loss: 0.001\n",
      "Epoch 14: Step [500/600], Loss: 0.021\n",
      "Epoch 14: Step [600/600], Loss: 0.001\n",
      "Epoch 15: Step [100/600], Loss: 0.001\n",
      "Epoch 15: Step [200/600], Loss: 0.003\n",
      "Epoch 15: Step [300/600], Loss: 0.002\n",
      "Epoch 15: Step [400/600], Loss: 0.002\n",
      "Epoch 15: Step [500/600], Loss: 0.001\n",
      "Epoch 15: Step [600/600], Loss: 0.002\n",
      "Epoch 16: Step [100/600], Loss: 0.006\n",
      "Epoch 16: Step [200/600], Loss: 0.001\n",
      "Epoch 16: Step [300/600], Loss: 0.003\n",
      "Epoch 16: Step [400/600], Loss: 0.009\n",
      "Epoch 16: Step [500/600], Loss: 0.010\n",
      "Epoch 16: Step [600/600], Loss: 0.000\n",
      "Epoch 17: Step [100/600], Loss: 0.002\n",
      "Epoch 17: Step [200/600], Loss: 0.028\n",
      "Epoch 17: Step [300/600], Loss: 0.011\n",
      "Epoch 17: Step [400/600], Loss: 0.001\n",
      "Epoch 17: Step [500/600], Loss: 0.005\n",
      "Epoch 17: Step [600/600], Loss: 0.029\n",
      "Epoch 18: Step [100/600], Loss: 0.001\n",
      "Epoch 18: Step [200/600], Loss: 0.001\n",
      "Epoch 18: Step [300/600], Loss: 0.010\n",
      "Epoch 18: Step [400/600], Loss: 0.001\n",
      "Epoch 18: Step [500/600], Loss: 0.003\n",
      "Epoch 18: Step [600/600], Loss: 0.000\n",
      "Epoch 19: Step [100/600], Loss: 0.002\n",
      "Epoch 19: Step [200/600], Loss: 0.076\n",
      "Epoch 19: Step [300/600], Loss: 0.001\n",
      "Epoch 19: Step [400/600], Loss: 0.000\n",
      "Epoch 19: Step [500/600], Loss: 0.007\n",
      "Epoch 19: Step [600/600], Loss: 0.000\n",
      "Epoch 20: Step [100/600], Loss: 0.003\n",
      "Epoch 20: Step [200/600], Loss: 0.001\n",
      "Epoch 20: Step [300/600], Loss: 0.000\n",
      "Epoch 20: Step [400/600], Loss: 0.000\n",
      "Epoch 20: Step [500/600], Loss: 0.001\n",
      "Epoch 20: Step [600/600], Loss: 0.003\n"
     ]
    }
   ],
   "source": [
    "# Creating the neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__() # Calling superconstructor\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.l1(x) # Pass thru Layer1\n",
    "        output = self.relu(output) # Applying ReLU activation function\n",
    "        output = self.l2(output) # Pass thru Layer2\n",
    "        return output # no activation function & no softmax at the end\n",
    "    \n",
    "model = NeuralNetwork(input_size, hidden_size, num_classes).to(device) # move to GPU\n",
    "\n",
    "# Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader): # iterating over the training set\n",
    "        # Reshaping input & moving to GPU\n",
    "        images = images.reshape(-1, 28*28).to(device) # (batch_size, features) --> each row is a training example\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backprop & optimizers\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Progress\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch {epoch + 1}: Step [{i+1}/{n_total_steps}], Loss: {loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c4a513c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 97.54% on the 10000 test image.\n"
     ]
    }
   ],
   "source": [
    "# Testing Model\n",
    "with torch.no_grad(): # no longer doing backprop, so don't need to computer gradients\n",
    "    n_correct = 0\n",
    "    n_samples = len(test_loader.dataset)\n",
    "\n",
    "    for images, labels in test_loader: \n",
    "        images = images.reshape(-1, 28*28).to(device) # X\n",
    "        labels = labels.to(device) # Y\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        # torch.max returns (max_values, indices_of_max_values)\n",
    "        _, predicted = torch.max(outputs, 1) # max value in outputs going across columns (1st dim)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = n_correct / n_samples\n",
    "    print(f\"Accuracy of {(accuracy*100):.2f}% on the {n_samples} test image.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93373089",
   "metadata": {},
   "source": [
    "### 5. CNN\n",
    "\n",
    "Concepts:\n",
    "* Convolutional layers\n",
    "* MaxPooling\n",
    "* Save/Load model\n",
    "\n",
    "\n",
    "Currently, I do not have the theoretical knowledge to implement a CNN and understand how it working.\n",
    "Because of that, I'm going to pivot to MIT's 6.S191 course to better learn theory, and implement what\n",
    "I learn in pytorch (rather than tensorflow, which is what the course uses). I'll be making a repo for \n",
    "that as well.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
